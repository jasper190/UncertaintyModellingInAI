{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from argparse import ArgumentParser\n",
    "from factor_utils import factor_evidence, factor_marginalize, assignment_to_index\n",
    "from factor import Factor\n",
    "\n",
    "# taken from part 1\n",
    "import copy\n",
    "import numpy as np\n",
    "from factor import Factor, index_to_assignment, assignment_to_index\n",
    "\n",
    "\n",
    "def factor_product(A, B):\n",
    "    \"\"\"\n",
    "    Computes the factor product of A and B e.g. A = f(x1, x2); B = f(x1, x3); out=f(x1, x2, x3) = f(x1, x2)f(x1, x3)\n",
    "\n",
    "    Args:\n",
    "        A: first Factor\n",
    "        B: second Factor\n",
    "\n",
    "    Returns:\n",
    "        Returns the factor product of A and B\n",
    "    \"\"\"\n",
    "    out = Factor()\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    if A.is_empty():\n",
    "        return B\n",
    "    if B.is_empty():\n",
    "        return A\n",
    "    # Create output factor. Variables should be the union between of the\n",
    "    # variables contained in the two input factors\n",
    "    out = Factor()\n",
    "    out.var = np.union1d(A.var, B.var)\n",
    "\n",
    "    # Compute mapping between the variable ordering between the two factors\n",
    "    # and the output to set the cardinality\n",
    "    out.card = np.zeros(len(out.var), np.int64)\n",
    "    mapA = np.argmax(out.var[None, :] == A.var[:, None], axis=-1)\n",
    "    mapB = np.argmax(out.var[None, :] == B.var[:, None], axis=-1)\n",
    "    out.card[mapA] = A.card\n",
    "    out.card[mapB] = B.card\n",
    "\n",
    "    # For each assignment in the output, compute which row of the input factors\n",
    "    # it comes from\n",
    "    out.val = np.zeros(np.prod(out.card))\n",
    "    assignments = out.get_all_assignments()\n",
    "    idxA = assignment_to_index(assignments[:, mapA], A.card)\n",
    "    idxB = assignment_to_index(assignments[:, mapB], B.card)\n",
    "\n",
    "    out.val = np.array(A.val)[idxA] * np.array(B.val)[idxB]\n",
    "    \"\"\" END YOUR CODE HERE \"\"\"\n",
    "    return out\n",
    "\n",
    "\n",
    "def factor_marginalize(factor, var):\n",
    "    \"\"\"\n",
    "    Returns factor after variables in var have been marginalized out.\n",
    "\n",
    "    Args:\n",
    "        factor: factor to be marginalized\n",
    "        var: numpy array of variables to be marginalized over\n",
    "\n",
    "    Returns:\n",
    "        marginalized factor\n",
    "    \"\"\"\n",
    "    out = copy.deepcopy(factor)\n",
    "\n",
    "    \"\"\" YOUR CODE HERE\n",
    "     HINT: Use the code from lab1 \"\"\"\n",
    "    out.var = np.setdiff1d(factor.var, var)\n",
    "    out.card = factor.card[np.isin(factor.var, out.var)]\n",
    "    out.val = np.zeros(np.prod(out.card))\n",
    "\n",
    "    unNormVar=np.squeeze(np.take(factor.get_all_assignments(),np.where(~np.isin(factor.var, var)),axis=1),axis=1)\n",
    "    unNormVarIndex = assignment_to_index(unNormVar, out.card)\n",
    "\n",
    "    unNormVal= [np.sum(np.array(factor.val)[unNormVarIndex == i]) for i in range(len(out.val))] \n",
    "    out.val=unNormVal/np.sum(unNormVal)\n",
    "    #out.val=unNormVal\n",
    "    \"\"\" END YOUR CODE HERE \"\"\"\n",
    "    return out\n",
    "\n",
    "\n",
    "def factor_evidence(factor, evidence):\n",
    "    \"\"\"\n",
    "    Observes evidence and retains entries containing the observed evidence. Also removes the evidence random variables\n",
    "    because they are already observed e.g. factor=f(1, 2) and evidence={1: 0} returns f(2) with entries from node1=0\n",
    "    Args:\n",
    "        factor: factor to reduce using evidence\n",
    "        evidence:  dictionary of node:evidence pair where evidence[1] = evidence of node 1.\n",
    "    Returns:\n",
    "        Reduced factor that does not contain any variables in the evidence. Return an empty factor if all the\n",
    "        factor's variables are observed.\n",
    "    \"\"\"\n",
    "    out = copy.deepcopy(factor)\n",
    "\n",
    "    \"\"\" YOUR CODE HERE,     HINT: copy from lab2 part 1! \"\"\"\n",
    "    for k in np.intersect1d(out.var,list(evidence.keys())):\n",
    "            # print(\"considering: \",k,evidence[k])\n",
    "            currentVarAssign=np.squeeze(np.take(out.get_all_assignments(),np.where(np.isin(out.var, k )),axis=1),axis=1)\n",
    "            indexesToChange=np.squeeze(np.where(np.any(currentVarAssign!=evidence[k], axis=1)))\n",
    "            out.val[indexesToChange]=0.0\n",
    "    \"\"\" END YOUR CODE HERE \"\"\"\n",
    "\n",
    "    return out\n",
    "\n",
    "def compute_joint_distribution(factors):\n",
    "    \"\"\"Computes the joint distribution defined by a list of given factors\n",
    "\n",
    "    Args:\n",
    "        factors (List[Factor]): List of factors\n",
    "\n",
    "    Returns:\n",
    "        Factor containing the joint distribution of the input factor list\n",
    "    \"\"\"\n",
    "    joint = Factor()\n",
    "\n",
    "    \"\"\" YOUR CODE HERE\n",
    "    Compute the joint distribution from the list of factors. You may assume\n",
    "    that the input factors are valid so no input checking is required.\n",
    "    \"\"\"\n",
    "    joint = factors[0]\n",
    "    if len(factors)<2:return joint\n",
    "\n",
    "    for factor in factors[1:]:\n",
    "        joint = factor_product(joint, factor)\n",
    "\n",
    "    return joint\n",
    "\n",
    "def update_factor_dict_with_evidence(factor, evidence):\n",
    "    \"\"\"\n",
    "    Observes evidence and retains entries containing the observed evidence. Also removes the evidence random variables\n",
    "    because they are already observed e.g. factor=f(1, 2) and evidence={1: 0} returns f(2) with entries from node1=0\n",
    "    Args:\n",
    "        factor: factor to reduce using evidence\n",
    "        evidence:  dictionary of node:evidence pair where evidence[1] = evidence of node 1.\n",
    "    Returns:\n",
    "        Reduced factor that does not contain any variables in the evidence. Return an empty factor if all the\n",
    "        factor's variables are observed.\n",
    "    \"\"\"\n",
    "    out = copy.deepcopy(factor)\n",
    "\n",
    "    \"\"\" YOUR CODE HERE,     HINT: copy from lab2 part 1! \"\"\"\n",
    "    holdingDict={}\n",
    "    for f in out.items():\n",
    "        factor=f[1]\n",
    "        node=f[0]\n",
    "        listToMarginalize=[]\n",
    "        for k in np.intersect1d(factor.var,list(evidence.keys())):\n",
    "            # print(\"considering: \",k,evidence[k])\n",
    "            currentVarAssign=np.squeeze(np.take(factor.get_all_assignments(),np.where(np.isin(factor.var, k )),axis=1),axis=1)\n",
    "            indexesToChange=np.squeeze(np.where(np.any(currentVarAssign!=evidence[k], axis=1)))\n",
    "            factor.val[indexesToChange]=0.0\n",
    "            #print(factor,k)\n",
    "            holdingDict[node]=k\n",
    "        if listToMarginalize:\n",
    "            holdingDict[node]=factor_marginalize(factor,listToMarginalize)\n",
    "        else:\n",
    "            holdingDict[node]=factor\n",
    "    out=holdingDict\n",
    "    \"\"\" END YOUR CODE HERE \"\"\"\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]),\n",
       " array([[0, 2],\n",
       "        [1, 2],\n",
       "        [2, 3],\n",
       "        [1, 4]]),\n",
       " {0: Factor containing 5 variables\n",
       "  -------------------------------------\n",
       "  | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       "  -------------------------------------\n",
       "  |  0   0   0   0   0  |   0.0138889 |\n",
       "  |  1   0   0   0   0  |   0.0277778 |\n",
       "  |  0   1   0   0   0  |  0.00543478 |\n",
       "  |  1   1   0   0   0  |   0.0362319 |\n",
       "  |  0   0   1   0   0  |   0.0367647 |\n",
       "  |  1   0   1   0   0  |  0.00490196 |\n",
       "  |  0   1   1   0   0  |   0.0231481 |\n",
       "  |  1   1   1   0   0  |   0.0185185 |\n",
       "  |  0   0   2   0   0  |   0.0398936 |\n",
       "  |  1   0   2   0   0  |  0.00177305 |\n",
       "  |  0   1   2   0   0  |       0.035 |\n",
       "  |  1   1   2   0   0  |  0.00666667 |\n",
       "  |  0   0   0   1   0  |   0.0138889 |\n",
       "  |  1   0   0   1   0  |   0.0277778 |\n",
       "  |  0   1   0   1   0  |  0.00543478 |\n",
       "  |  1   1   0   1   0  |   0.0362319 |\n",
       "  |  0   0   1   1   0  |   0.0367647 |\n",
       "  |  1   0   1   1   0  |  0.00490196 |\n",
       "  |  0   1   1   1   0  |   0.0231481 |\n",
       "  |  1   1   1   1   0  |   0.0185185 |\n",
       "  |  0   0   2   1   0  |   0.0398936 |\n",
       "  |  1   0   2   1   0  |  0.00177305 |\n",
       "  |  0   1   2   1   0  |       0.035 |\n",
       "  |  1   1   2   1   0  |  0.00666667 |\n",
       "  |  0   0   0   0   1  |   0.0138889 |\n",
       "  |  1   0   0   0   1  |   0.0277778 |\n",
       "  |  0   1   0   0   1  |  0.00543478 |\n",
       "  |  1   1   0   0   1  |   0.0362319 |\n",
       "  |  0   0   1   0   1  |   0.0367647 |\n",
       "  |  1   0   1   0   1  |  0.00490196 |\n",
       "  |  0   1   1   0   1  |   0.0231481 |\n",
       "  |  1   1   1   0   1  |   0.0185185 |\n",
       "  |  0   0   2   0   1  |   0.0398936 |\n",
       "  |  1   0   2   0   1  |  0.00177305 |\n",
       "  |  0   1   2   0   1  |       0.035 |\n",
       "  |  1   1   2   0   1  |  0.00666667 |\n",
       "  |  0   0   0   1   1  |   0.0138889 |\n",
       "  |  1   0   0   1   1  |   0.0277778 |\n",
       "  |  0   1   0   1   1  |  0.00543478 |\n",
       "  |  1   1   0   1   1  |   0.0362319 |\n",
       "  |  0   0   1   1   1  |   0.0367647 |\n",
       "  |  1   0   1   1   1  |  0.00490196 |\n",
       "  |  0   1   1   1   1  |   0.0231481 |\n",
       "  |  1   1   1   1   1  |   0.0185185 |\n",
       "  |  0   0   2   1   1  |   0.0398936 |\n",
       "  |  1   0   2   1   1  |  0.00177305 |\n",
       "  |  0   1   2   1   1  |       0.035 |\n",
       "  |  1   1   2   1   1  |  0.00666667 |\n",
       "  -------------------------------------\n",
       "  ,\n",
       "  1: Factor containing 5 variables\n",
       "  -------------------------------------\n",
       "  | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       "  -------------------------------------\n",
       "  |  0   0   0   0   0  |   0.0410494 |\n",
       "  |  1   0   0   0   0  |   0.0396778 |\n",
       "  |  0   1   0   0   0  | 0.000617284 |\n",
       "  |  1   1   0   0   0  |  0.00198886 |\n",
       "  |  0   0   1   0   0  |   0.0394425 |\n",
       "  |  1   0   1   0   0  |    0.031133 |\n",
       "  |  0   1   1   0   0  |   0.0022242 |\n",
       "  |  1   1   1   0   0  |   0.0105337 |\n",
       "  |  0   0   2   0   0  |   0.0344203 |\n",
       "  |  1   0   2   0   0  |   0.0219038 |\n",
       "  |  0   1   2   0   0  |  0.00724638 |\n",
       "  |  1   1   2   0   0  |   0.0197628 |\n",
       "  |  0   0   0   1   0  |   0.0410494 |\n",
       "  |  1   0   0   1   0  |   0.0396778 |\n",
       "  |  0   1   0   1   0  | 0.000617284 |\n",
       "  |  1   1   0   1   0  |  0.00198886 |\n",
       "  |  0   0   1   1   0  |   0.0394425 |\n",
       "  |  1   0   1   1   0  |    0.031133 |\n",
       "  |  0   1   1   1   0  |   0.0022242 |\n",
       "  |  1   1   1   1   0  |   0.0105337 |\n",
       "  |  0   0   2   1   0  |   0.0344203 |\n",
       "  |  1   0   2   1   0  |   0.0219038 |\n",
       "  |  0   1   2   1   0  |  0.00724638 |\n",
       "  |  1   1   2   1   0  |   0.0197628 |\n",
       "  |  0   0   0   0   1  |   0.0194444 |\n",
       "  |  1   0   0   0   1  |  0.00866337 |\n",
       "  |  0   1   0   0   1  |   0.0222222 |\n",
       "  |  1   1   0   0   1  |   0.0330033 |\n",
       "  |  0   0   1   0   1  |  0.00788288 |\n",
       "  |  1   0   1   0   1  |  0.00155971 |\n",
       "  |  0   1   1   0   1  |   0.0337838 |\n",
       "  |  1   1   1   0   1  |    0.040107 |\n",
       "  |  0   0   2   0   1  |  0.00245098 |\n",
       "  |  1   0   2   0   1  | 0.000598905 |\n",
       "  |  0   1   2   0   1  |   0.0392157 |\n",
       "  |  1   1   2   0   1  |   0.0410678 |\n",
       "  |  0   0   0   1   1  |   0.0194444 |\n",
       "  |  1   0   0   1   1  |  0.00866337 |\n",
       "  |  0   1   0   1   1  |   0.0222222 |\n",
       "  |  1   1   0   1   1  |   0.0330033 |\n",
       "  |  0   0   1   1   1  |  0.00788288 |\n",
       "  |  1   0   1   1   1  |  0.00155971 |\n",
       "  |  0   1   1   1   1  |   0.0337838 |\n",
       "  |  1   1   1   1   1  |    0.040107 |\n",
       "  |  0   0   2   1   1  |  0.00245098 |\n",
       "  |  1   0   2   1   1  | 0.000598905 |\n",
       "  |  0   1   2   1   1  |   0.0392157 |\n",
       "  |  1   1   2   1   1  |   0.0410678 |\n",
       "  -------------------------------------\n",
       "  ,\n",
       "  2: Factor containing 5 variables\n",
       "  -------------------------------------\n",
       "  | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       "  -------------------------------------\n",
       "  |  0   0   0   0   0  |   0.0038501 |\n",
       "  |  1   0   0   0   0  |   0.0396685 |\n",
       "  |  0   1   0   0   0  | 0.000391604 |\n",
       "  |  1   1   0   0   0  |  0.00849185 |\n",
       "  |  0   0   1   0   0  |   0.0205339 |\n",
       "  |  1   0   1   0   0  |   0.0141044 |\n",
       "  |  0   1   1   0   0  |  0.00783208 |\n",
       "  |  1   1   1   0   0  |   0.0203804 |\n",
       "  |  0   0   2   0   0  |    0.038116 |\n",
       "  |  1   0   2   0   0  |  0.00872708 |\n",
       "  |  0   1   2   0   0  |   0.0542763 |\n",
       "  |  1   1   2   0   0  |   0.0336277 |\n",
       "  |  0   0   0   1   0  |   0.0328947 |\n",
       "  |  1   0   0   1   0  |   0.0589897 |\n",
       "  |  0   1   0   1   0  |   0.0139233 |\n",
       "  |  1   1   0   1   0  |   0.0445016 |\n",
       "  |  0   0   1   1   0  |   0.0292398 |\n",
       "  |  1   0   1   1   0  |  0.00349569 |\n",
       "  |  0   1   1   1   0  |   0.0464109 |\n",
       "  |  1   1   1   1   0  |   0.0178006 |\n",
       "  |  0   0   2   1   0  | 0.000365497 |\n",
       "  |  1   0   2   1   0  | 1.45654e-05 |\n",
       "  |  0   1   2   1   0  |  0.00216584 |\n",
       "  |  1   1   2   1   0  | 0.000197785 |\n",
       "  |  0   0   0   0   1  |   0.0038501 |\n",
       "  |  1   0   0   0   1  |   0.0396685 |\n",
       "  |  0   1   0   0   1  | 0.000391604 |\n",
       "  |  1   1   0   0   1  |  0.00849185 |\n",
       "  |  0   0   1   0   1  |   0.0205339 |\n",
       "  |  1   0   1   0   1  |   0.0141044 |\n",
       "  |  0   1   1   0   1  |  0.00783208 |\n",
       "  |  1   1   1   0   1  |   0.0203804 |\n",
       "  |  0   0   2   0   1  |    0.038116 |\n",
       "  |  1   0   2   0   1  |  0.00872708 |\n",
       "  |  0   1   2   0   1  |   0.0542763 |\n",
       "  |  1   1   2   0   1  |   0.0336277 |\n",
       "  |  0   0   0   1   1  |   0.0328947 |\n",
       "  |  1   0   0   1   1  |   0.0589897 |\n",
       "  |  0   1   0   1   1  |   0.0139233 |\n",
       "  |  1   1   0   1   1  |   0.0445016 |\n",
       "  |  0   0   1   1   1  |   0.0292398 |\n",
       "  |  1   0   1   1   1  |  0.00349569 |\n",
       "  |  0   1   1   1   1  |   0.0464109 |\n",
       "  |  1   1   1   1   1  |   0.0178006 |\n",
       "  |  0   0   2   1   1  | 0.000365497 |\n",
       "  |  1   0   2   1   1  | 1.45654e-05 |\n",
       "  |  0   1   2   1   1  |  0.00216584 |\n",
       "  |  1   1   2   1   1  | 0.000197785 |\n",
       "  -------------------------------------\n",
       "  ,\n",
       "  3: Factor containing 5 variables\n",
       "  -------------------------------------\n",
       "  | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       "  -------------------------------------\n",
       "  |  0   0   0   0   0  |  0.00416667 |\n",
       "  |  1   0   0   0   0  |  0.00416667 |\n",
       "  |  0   1   0   0   0  |  0.00416667 |\n",
       "  |  1   1   0   0   0  |  0.00416667 |\n",
       "  |  0   0   1   0   0  |   0.0166667 |\n",
       "  |  1   0   1   0   0  |   0.0166667 |\n",
       "  |  0   1   1   0   0  |   0.0166667 |\n",
       "  |  1   1   1   0   0  |   0.0166667 |\n",
       "  |  0   0   2   0   0  |     0.04125 |\n",
       "  |  1   0   2   0   0  |     0.04125 |\n",
       "  |  0   1   2   0   0  |     0.04125 |\n",
       "  |  1   1   2   0   0  |     0.04125 |\n",
       "  |  0   0   0   1   0  |      0.0375 |\n",
       "  |  1   0   0   1   0  |      0.0375 |\n",
       "  |  0   1   0   1   0  |      0.0375 |\n",
       "  |  1   1   0   1   0  |      0.0375 |\n",
       "  |  0   0   1   1   0  |       0.025 |\n",
       "  |  1   0   1   1   0  |       0.025 |\n",
       "  |  0   1   1   1   0  |       0.025 |\n",
       "  |  1   1   1   1   0  |       0.025 |\n",
       "  |  0   0   2   1   0  | 0.000416667 |\n",
       "  |  1   0   2   1   0  | 0.000416667 |\n",
       "  |  0   1   2   1   0  | 0.000416667 |\n",
       "  |  1   1   2   1   0  | 0.000416667 |\n",
       "  |  0   0   0   0   1  |  0.00416667 |\n",
       "  |  1   0   0   0   1  |  0.00416667 |\n",
       "  |  0   1   0   0   1  |  0.00416667 |\n",
       "  |  1   1   0   0   1  |  0.00416667 |\n",
       "  |  0   0   1   0   1  |   0.0166667 |\n",
       "  |  1   0   1   0   1  |   0.0166667 |\n",
       "  |  0   1   1   0   1  |   0.0166667 |\n",
       "  |  1   1   1   0   1  |   0.0166667 |\n",
       "  |  0   0   2   0   1  |     0.04125 |\n",
       "  |  1   0   2   0   1  |     0.04125 |\n",
       "  |  0   1   2   0   1  |     0.04125 |\n",
       "  |  1   1   2   0   1  |     0.04125 |\n",
       "  |  0   0   0   1   1  |      0.0375 |\n",
       "  |  1   0   0   1   1  |      0.0375 |\n",
       "  |  0   1   0   1   1  |      0.0375 |\n",
       "  |  1   1   0   1   1  |      0.0375 |\n",
       "  |  0   0   1   1   1  |       0.025 |\n",
       "  |  1   0   1   1   1  |       0.025 |\n",
       "  |  0   1   1   1   1  |       0.025 |\n",
       "  |  1   1   1   1   1  |       0.025 |\n",
       "  |  0   0   2   1   1  | 0.000416667 |\n",
       "  |  1   0   2   1   1  | 0.000416667 |\n",
       "  |  0   1   2   1   1  | 0.000416667 |\n",
       "  |  1   1   2   1   1  | 0.000416667 |\n",
       "  -------------------------------------\n",
       "  ,\n",
       "  4: Factor containing 5 variables\n",
       "  -------------------------------------\n",
       "  | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       "  -------------------------------------\n",
       "  |  0   0   0   0   0  |   0.0395833 |\n",
       "  |  1   0   0   0   0  |   0.0395833 |\n",
       "  |  0   1   0   0   0  |  0.00833333 |\n",
       "  |  1   1   0   0   0  |  0.00833333 |\n",
       "  |  0   0   1   0   0  |   0.0395833 |\n",
       "  |  1   0   1   0   0  |   0.0395833 |\n",
       "  |  0   1   1   0   0  |  0.00833333 |\n",
       "  |  1   1   1   0   0  |  0.00833333 |\n",
       "  |  0   0   2   0   0  |   0.0395833 |\n",
       "  |  1   0   2   0   0  |   0.0395833 |\n",
       "  |  0   1   2   0   0  |  0.00833333 |\n",
       "  |  1   1   2   0   0  |  0.00833333 |\n",
       "  |  0   0   0   1   0  |   0.0395833 |\n",
       "  |  1   0   0   1   0  |   0.0395833 |\n",
       "  |  0   1   0   1   0  |  0.00833333 |\n",
       "  |  1   1   0   1   0  |  0.00833333 |\n",
       "  |  0   0   1   1   0  |   0.0395833 |\n",
       "  |  1   0   1   1   0  |   0.0395833 |\n",
       "  |  0   1   1   1   0  |  0.00833333 |\n",
       "  |  1   1   1   1   0  |  0.00833333 |\n",
       "  |  0   0   2   1   0  |   0.0395833 |\n",
       "  |  1   0   2   1   0  |   0.0395833 |\n",
       "  |  0   1   2   1   0  |  0.00833333 |\n",
       "  |  1   1   2   1   0  |  0.00833333 |\n",
       "  |  0   0   0   0   1  |  0.00208333 |\n",
       "  |  1   0   0   0   1  |  0.00208333 |\n",
       "  |  0   1   0   0   1  |   0.0333333 |\n",
       "  |  1   1   0   0   1  |   0.0333333 |\n",
       "  |  0   0   1   0   1  |  0.00208333 |\n",
       "  |  1   0   1   0   1  |  0.00208333 |\n",
       "  |  0   1   1   0   1  |   0.0333333 |\n",
       "  |  1   1   1   0   1  |   0.0333333 |\n",
       "  |  0   0   2   0   1  |  0.00208333 |\n",
       "  |  1   0   2   0   1  |  0.00208333 |\n",
       "  |  0   1   2   0   1  |   0.0333333 |\n",
       "  |  1   1   2   0   1  |   0.0333333 |\n",
       "  |  0   0   0   1   1  |  0.00208333 |\n",
       "  |  1   0   0   1   1  |  0.00208333 |\n",
       "  |  0   1   0   1   1  |   0.0333333 |\n",
       "  |  1   1   0   1   1  |   0.0333333 |\n",
       "  |  0   0   1   1   1  |  0.00208333 |\n",
       "  |  1   0   1   1   1  |  0.00208333 |\n",
       "  |  0   1   1   1   1  |   0.0333333 |\n",
       "  |  1   1   1   1   1  |   0.0333333 |\n",
       "  |  0   0   2   1   1  |  0.00208333 |\n",
       "  |  1   0   2   1   1  |  0.00208333 |\n",
       "  |  0   1   2   1   1  |   0.0333333 |\n",
       "  |  1   1   2   1   1  |   0.0333333 |\n",
       "  -------------------------------------\n",
       "  },\n",
       " {2: 1},\n",
       " {0: 0, 1: 0, 2: 0, 3: 0, 4: 0},\n",
       " 10000,\n",
       " 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_input_file(input_file: str) -> (Factor, dict, dict, int):\n",
    "    \"\"\"\n",
    "    Returns the target factor, proposal factors for each node and evidence. DO NOT EDIT THIS FUNCTION\n",
    "\n",
    "    Args:\n",
    "        input_file: input file to open\n",
    "\n",
    "    Returns:\n",
    "        Factor of the target factor which is the target joint distribution of all nodes in the Bayesian network\n",
    "        dictionary of node:Factor pair where Factor is the proposal distribution to sample node observations. Other\n",
    "                    nodes in the Factor are parent nodes of the node\n",
    "        dictionary of node:val pair where node is an evidence node while val is the evidence for the node.\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        input_config = json.load(f)\n",
    "    proposal_factors_dict = input_config['proposal-factors']\n",
    "\n",
    "    def parse_factor_dict(factor_dict):\n",
    "        var = np.array(factor_dict['var'])\n",
    "        card = np.array(factor_dict['card'])\n",
    "        val = np.array(factor_dict['val'])\n",
    "        return Factor(var=var, card=card, val=val)\n",
    "\n",
    "    nodes = np.array(input_config['nodes'], dtype=int)\n",
    "    edges = np.array(input_config['edges'], dtype=int)\n",
    "    node_factors = {int(node): parse_factor_dict(factor_dict=proposal_factor_dict) for\n",
    "                    node, proposal_factor_dict in proposal_factors_dict.items()}\n",
    "\n",
    "    evidence = {int(node): ev for node, ev in input_config['evidence'].items()}\n",
    "    initial_samples = {int(node): initial for node, initial in input_config['initial-samples'].items()}\n",
    "\n",
    "    num_iterations = input_config['num-iterations']\n",
    "    num_burn_in = input_config['num-burn-in']\n",
    "    return nodes, edges, node_factors, evidence, initial_samples, num_iterations, num_burn_in\n",
    "\n",
    "os.getcwd()+\"/data\"\n",
    "\n",
    "testcase=\"2\"\n",
    "nodes, edges, node_factors, evidence, initial_samples, num_iterations, num_burn_in = load_input_file(input_file=\"/home/jasper/programming/lab4/lab4/part2/data/inputs/\"+testcase+\".json\")\n",
    "nodes, edges, node_factors, evidence, initial_samples, num_iterations, num_burn_in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [[0 2]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [1 4]]\n",
      "0 [0, 2]\n",
      "Factor containing 2 variables\n",
      "-------------------------\n",
      "| X_0 X_2 | Probability |\n",
      "-------------------------\n",
      "|  0   0  |   0.0772947 |\n",
      "|  1   0  |    0.256039 |\n",
      "|  0   1  |    0.239651 |\n",
      "|  1   1  |   0.0936819 |\n",
      "|  0   2  |    0.299574 |\n",
      "|  1   2  |   0.0337589 |\n",
      "-------------------------\n",
      "\n",
      "\n",
      "1 [1, 2, 4]\n",
      "Factor containing 3 variables\n",
      "-----------------------------\n",
      "| X_1 X_2 X_4 | Probability |\n",
      "-----------------------------\n",
      "|  0   0   0  |    0.161454 |\n",
      "|  1   0   0  |  0.00521229 |\n",
      "|  0   1   0  |    0.141151 |\n",
      "|  1   1   0  |   0.0255158 |\n",
      "|  0   2   0  |    0.112648 |\n",
      "|  1   2   0  |   0.0540184 |\n",
      "|  0   0   1  |   0.0562156 |\n",
      "|  1   0   1  |    0.110451 |\n",
      "|  0   1   1  |   0.0188852 |\n",
      "|  1   1   1  |    0.147781 |\n",
      "|  0   2   1  |  0.00609977 |\n",
      "|  1   2   1  |    0.160567 |\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "2 [2, 3]\n",
      "Factor containing 2 variables\n",
      "-------------------------\n",
      "| X_2 X_3 | Probability |\n",
      "-------------------------\n",
      "|  0   0  |    0.104804 |\n",
      "|  1   0  |    0.125702 |\n",
      "|  2   0  |    0.269494 |\n",
      "|  0   1  |    0.300619 |\n",
      "|  1   1  |    0.193894 |\n",
      "|  2   1  |  0.00548738 |\n",
      "-------------------------\n",
      "\n",
      "\n",
      "3 [3]\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_3 | Probability |\n",
      "---------------------\n",
      "|  0  |    0.496667 |\n",
      "|  1  |    0.503333 |\n",
      "---------------------\n",
      "\n",
      "\n",
      "4 [4]\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_4 | Probability |\n",
      "---------------------\n",
      "|  0  |       0.575 |\n",
      "|  1  |       0.425 |\n",
      "---------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1687.67it/s]\n",
      "100%|██████████| 10000/10000 [00:05<00:00, 1732.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Factor containing 5 variables\n",
       "-------------------------------------\n",
       "| X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       "-------------------------------------\n",
       "|  0   0   0   0   0  |      0.0377 |\n",
       "|  1   0   0   0   0  |      0.0049 |\n",
       "|  0   1   0   0   0  |      0.0161 |\n",
       "|  1   1   0   0   0  |      0.0017 |\n",
       "|  0   0   1   0   0  |      0.0441 |\n",
       "|  1   0   1   0   0  |      0.0051 |\n",
       "|  0   1   1   0   0  |      0.0207 |\n",
       "|  1   1   1   0   0  |       0.003 |\n",
       "|  0   0   2   0   0  |      0.0918 |\n",
       "|  1   0   2   0   0  |      0.0117 |\n",
       "|  0   1   2   0   0  |      0.0467 |\n",
       "|  1   1   2   0   0  |      0.0055 |\n",
       "|  0   0   0   1   0  |      0.0382 |\n",
       "|  1   0   0   1   0  |      0.0033 |\n",
       "|  0   1   0   1   0  |      0.0165 |\n",
       "|  1   1   0   1   0  |       0.002 |\n",
       "|  0   0   1   1   0  |      0.0419 |\n",
       "|  1   0   1   1   0  |      0.0054 |\n",
       "|  0   1   1   1   0  |      0.0219 |\n",
       "|  1   1   1   1   0  |      0.0024 |\n",
       "|  0   0   2   1   0  |      0.0903 |\n",
       "|  1   0   2   1   0  |      0.0113 |\n",
       "|  0   1   2   1   0  |      0.0498 |\n",
       "|  1   1   2   1   0  |      0.0054 |\n",
       "|  0   0   0   0   1  |      0.0283 |\n",
       "|  1   0   0   0   1  |      0.0039 |\n",
       "|  0   1   0   0   1  |      0.0132 |\n",
       "|  1   1   0   0   1  |      0.0014 |\n",
       "|  0   0   1   0   1  |      0.0329 |\n",
       "|  1   0   1   0   1  |      0.0035 |\n",
       "|  0   1   1   0   1  |      0.0147 |\n",
       "|  1   1   1   0   1  |      0.0016 |\n",
       "|  0   0   2   0   1  |      0.0659 |\n",
       "|  1   0   2   0   1  |      0.0082 |\n",
       "|  0   1   2   0   1  |      0.0328 |\n",
       "|  1   1   2   0   1  |      0.0036 |\n",
       "|  0   0   0   1   1  |      0.0242 |\n",
       "|  1   0   0   1   1  |      0.0029 |\n",
       "|  0   1   0   1   1  |      0.0141 |\n",
       "|  1   1   0   1   1  |      0.0012 |\n",
       "|  0   0   1   1   1  |      0.0323 |\n",
       "|  1   0   1   1   1  |      0.0046 |\n",
       "|  0   1   1   1   1  |      0.0164 |\n",
       "|  1   1   1   1   1  |      0.0025 |\n",
       "|  0   0   2   1   1  |      0.0729 |\n",
       "|  1   0   2   1   1  |      0.0066 |\n",
       "|  0   1   2   1   1  |      0.0311 |\n",
       "|  1   1   2   1   1  |      0.0038 |\n",
       "-------------------------------------\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#ver 1: assuming factors\n",
    "\n",
    "def _sample_step(nodes, factors, in_samples):\n",
    "    \"\"\"\n",
    "    Performs gibbs sampling for a single iteration. Returns a sample for each node\n",
    "\n",
    "    Args:\n",
    "        nodes: numpy array of nodes\n",
    "        factors: dictionary of factors e.g. factors[x1] returns the local factor for x1\n",
    "        in_samples: dictionary of input samples (from previous iteration)\n",
    "\n",
    "    Returns:\n",
    "        dictionary of output samples where samples[x1] returns the sample for x1.\n",
    "    \"\"\"\n",
    "    samples = copy.deepcopy(in_samples)\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    for node in nodes:\n",
    "        currentVariable=node\n",
    "        fixedVariablesDict={k:v for k,v in samples.items() if k!=currentVariable}\n",
    "        #evidence is a problem\n",
    "        currentFactor=factor_evidence(factors[currentVariable],fixedVariablesDict)\n",
    "        variable_factor=factor_marginalize(currentFactor,np.setdiff1d(currentFactor.var, [currentVariable]) )\n",
    "        # print(node,currentFactor.var, [currentVariable],np.setdiff1d(currentFactor.var, [currentVariable]) )\n",
    "        proposal_distribution = variable_factor.val\n",
    "        sample_space = np.arange(len(proposal_distribution))\n",
    "        # Sample a value using the proposal distribution\n",
    "        sampled_value = np.random.choice(sample_space, p=proposal_distribution)\n",
    "        samples[node]=sampled_value\n",
    "        #print(variable_factor,sampled_value,current_samples)\n",
    "\n",
    "    \"\"\" END YOUR CODE HERE \"\"\"\n",
    "\n",
    "    return samples\n",
    "\n",
    "def _get_conditional_probability(nodes, edges, factors, evidence, initial_samples, num_iterations, num_burn_in):\n",
    "    \"\"\"\n",
    "    Returns the conditional probability p(Xf | Xe) where Xe is the set of observed nodes and Xf are the query nodes\n",
    "    i.e. the unobserved nodes. The conditional probability is approximated using Gibbs sampling.\n",
    "\n",
    "    Args:\n",
    "        nodes: numpy array of nodes e.g. [x1, x2, ...].\n",
    "        edges: numpy array of edges e.g. [i, j] implies that nodes[i] is the parent of nodes[j].\n",
    "        factors: dictionary of Factors e.g. factors[x1] returns the conditional probability of x1 given all other nodes.\n",
    "        evidence: dictionary of evidence e.g. evidence[x4] returns the provided evidence for x4.\n",
    "        initial_samples: dictionary of initial samples to initialize Gibbs sampling.\n",
    "        num_iterations: number of sampling iterations\n",
    "        num_burn_in: number of burn-in iterations\n",
    "\n",
    "    Returns:\n",
    "        returns Factor of conditional probability.\n",
    "    \"\"\"\n",
    "    assert num_iterations > num_burn_in\n",
    "    conditional_prob = Factor()\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    print(nodes,edges)\n",
    "    #update evidence\n",
    "    evidencedFactorsDict=update_factor_dict_with_evidence(factors,evidence)\n",
    "    evidencedFactorsDict\n",
    "    # create children dict\n",
    "    markovBlanketDict= {node:[node]+[child for parent,child in edges if parent==node] for node in nodes}\n",
    "    markovBlanketSeperatedFactors={}\n",
    "    # finding valid nodes post markov blankets treatment\n",
    "    for node in markovBlanketDict.keys():\n",
    "        factorsToMarginalizeOutList=np.setdiff1d(evidencedFactorsDict[node].var, markovBlanketDict[node])\n",
    "        print(node,markovBlanketDict[node])\n",
    "        markovBlanketSeperatedFactors[node]=factor_marginalize(evidencedFactorsDict[node],factorsToMarginalizeOutList)\n",
    "        print(markovBlanketSeperatedFactors[node])\n",
    "\n",
    "    start_samples=copy.deepcopy(initial_samples)\n",
    "    for key in start_samples.keys():\n",
    "        if evidence.get(key):\n",
    "            start_samples[key]=evidence[key]\n",
    "\n",
    "    burnedInSamples={}\n",
    "    # num_iterations, num_burn_in\n",
    "    for _ in tqdm(range(num_burn_in)):\n",
    "        burnedInSamples=_sample_step(nodes=nodes, factors=markovBlanketSeperatedFactors, in_samples=start_samples)\n",
    "\n",
    "    samplesList=[]\n",
    "    for _ in tqdm(range(num_iterations)):\n",
    "        samplesList.append(_sample_step(nodes=nodes, factors=markovBlanketSeperatedFactors, in_samples=burnedInSamples))\n",
    "    df1=pd.DataFrame(samplesList)\n",
    "    grouped = df1.groupby(list(df1.columns)).size().reset_index(name='counts')\n",
    "    problemVal=np.zeros(len(node_factors[0].val))\n",
    "    problemVal[grouped.apply(lambda x: assignment_to_index(x[df1.columns].to_numpy(),node_factors[0].card),axis=1)]=grouped.counts\n",
    "\n",
    "    conditional_prob=Factor(var=factors[0].var,card=factors[0].card,val=problemVal/np.sum(problemVal))\n",
    "\n",
    "\n",
    "    \"\"\" END YOUR CODE HERE \"\"\"\n",
    "\n",
    "    return conditional_prob\n",
    "\n",
    "conditional_probability = _get_conditional_probability(nodes=nodes, edges=edges, factors=node_factors,\n",
    "                                                           evidence=evidence, initial_samples=initial_samples,\n",
    "                                                           num_iterations=num_iterations, num_burn_in=num_burn_in)\n",
    "\n",
    "conditional_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [[0 2]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [1 4]]\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_0 | Probability |\n",
      "---------------------\n",
      "|  0  |    0.616521 |\n",
      "|  1  |    0.383479 |\n",
      "---------------------\n",
      "\n",
      "\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_1 | Probability |\n",
      "---------------------\n",
      "|  0  |    0.496454 |\n",
      "|  1  |    0.503546 |\n",
      "---------------------\n",
      "\n",
      "\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_2 | Probability |\n",
      "---------------------\n",
      "|  0  |    0.405423 |\n",
      "|  1  |    0.319595 |\n",
      "|  2  |    0.274982 |\n",
      "---------------------\n",
      "\n",
      "\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_3 | Probability |\n",
      "---------------------\n",
      "|  0  |    0.496667 |\n",
      "|  1  |    0.503333 |\n",
      "---------------------\n",
      "\n",
      "\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_4 | Probability |\n",
      "---------------------\n",
      "|  0  |       0.575 |\n",
      "|  1  |       0.425 |\n",
      "---------------------\n",
      "\n",
      "\n",
      "0 [0, 2]\n",
      "Factor containing 2 variables\n",
      "-------------------------\n",
      "| X_0 X_2 | Probability |\n",
      "-------------------------\n",
      "|  0   0  |           0 |\n",
      "|  1   0  |           0 |\n",
      "|  0   1  |    0.795473 |\n",
      "|  1   1  |    0.204527 |\n",
      "|  0   2  |           0 |\n",
      "|  1   2  |           0 |\n",
      "-------------------------\n",
      "\n",
      "\n",
      "1 [1, 2, 4]\n",
      "Factor containing 3 variables\n",
      "-----------------------------\n",
      "| X_1 X_2 X_4 | Probability |\n",
      "-----------------------------\n",
      "|  0   0   0  |           0 |\n",
      "|  1   0   0  |           0 |\n",
      "|  0   1   0  |    0.458569 |\n",
      "|  1   1   0  |   0.0201005 |\n",
      "|  0   2   0  |           0 |\n",
      "|  1   2   0  |           0 |\n",
      "|  0   0   1  |           0 |\n",
      "|  1   0   1  |           0 |\n",
      "|  0   1   1  |  0.00403492 |\n",
      "|  1   1   1  |    0.517295 |\n",
      "|  0   2   1  |           0 |\n",
      "|  1   2   1  |           0 |\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "3 [3]\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_3 | Probability |\n",
      "---------------------\n",
      "|  0  |         0.4 |\n",
      "|  1  |         0.6 |\n",
      "---------------------\n",
      "\n",
      "\n",
      "4 [4]\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_4 | Probability |\n",
      "---------------------\n",
      "|  0  |       0.575 |\n",
      "|  1  |       0.425 |\n",
      "---------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2697.85it/s]\n",
      "100%|██████████| 9000/9000 [00:03<00:00, 2676.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Factor containing 4 variables\n",
       "---------------------------------\n",
       "| X_0 X_1 X_3 X_4 | Probability |\n",
       "---------------------------------\n",
       "|  0   0   0   0  |   0.0858889 |\n",
       "|  1   0   0   0  |   0.0537778 |\n",
       "|  0   1   0   0  |   0.0868889 |\n",
       "|  1   1   0   0  |   0.0561111 |\n",
       "|  0   0   1   0  |   0.0894444 |\n",
       "|  1   0   1   0  |        0.06 |\n",
       "|  0   1   1   0  |   0.0905556 |\n",
       "|  1   1   1   0  |   0.0573333 |\n",
       "|  0   0   0   1  |   0.0605556 |\n",
       "|  1   0   0   1  |       0.041 |\n",
       "|  0   1   0   1  |   0.0638889 |\n",
       "|  1   1   0   1  |   0.0405556 |\n",
       "|  0   0   1   1  |   0.0658889 |\n",
       "|  1   0   1   1  |   0.0396667 |\n",
       "|  0   1   1   1  |   0.0641111 |\n",
       "|  1   1   1   1  |   0.0443333 |\n",
       "---------------------------------\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#ver 2: assuming factors\n",
    "\n",
    "def _sample_step(nodes, factors, in_samples):\n",
    "    \"\"\"\n",
    "    Performs gibbs sampling for a single iteration. Returns a sample for each node\n",
    "\n",
    "    Args:\n",
    "        nodes: numpy array of nodes\n",
    "        factors: dictionary of factors e.g. factors[x1] returns the local factor for x1\n",
    "        in_samples: dictionary of input samples (from previous iteration)\n",
    "\n",
    "    Returns:\n",
    "        dictionary of output samples where samples[x1] returns the sample for x1.\n",
    "    \"\"\"\n",
    "    samples = copy.deepcopy(in_samples)\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    for node in nodes:\n",
    "        currentVariable=node\n",
    "        fixedVariablesDict={k:v for k,v in samples.items() if k!=currentVariable}\n",
    "        #evidence is a problem\n",
    "        currentFactor=factor_evidence(factors[currentVariable],fixedVariablesDict)\n",
    "        variable_factor=factor_marginalize(currentFactor,np.setdiff1d(currentFactor.var, [currentVariable]) )\n",
    "        # print(node,currentFactor.var, [currentVariable],np.setdiff1d(currentFactor.var, [currentVariable]) )\n",
    "        proposal_distribution = variable_factor.val\n",
    "        sample_space = np.arange(len(proposal_distribution))\n",
    "        # Sample a value using the proposal distribution\n",
    "        sampled_value = np.random.choice(sample_space, p=proposal_distribution)\n",
    "        samples[node]=sampled_value\n",
    "        #print(variable_factor,sampled_value,current_samples)\n",
    "\n",
    "    \"\"\" END YOUR CODE HERE \"\"\"\n",
    "\n",
    "    return samples\n",
    "\n",
    "def _get_conditional_probability(nodes, edges, factors, evidence, initial_samples, num_iterations, num_burn_in):\n",
    "    \"\"\"\n",
    "    Returns the conditional probability p(Xf | Xe) where Xe is the set of observed nodes and Xf are the query nodes\n",
    "    i.e. the unobserved nodes. The conditional probability is approximated using Gibbs sampling.\n",
    "\n",
    "    Args:\n",
    "        nodes: numpy array of nodes e.g. [x1, x2, ...].\n",
    "        edges: numpy array of edges e.g. [i, j] implies that nodes[i] is the parent of nodes[j].\n",
    "        factors: dictionary of Factors e.g. factors[x1] returns the conditional probability of x1 given all other nodes.\n",
    "        evidence: dictionary of evidence e.g. evidence[x4] returns the provided evidence for x4.\n",
    "        initial_samples: dictionary of initial samples to initialize Gibbs sampling.\n",
    "        num_iterations: number of sampling iterations\n",
    "        num_burn_in: number of burn-in iterations\n",
    "\n",
    "    Returns:\n",
    "        returns Factor of conditional probability.\n",
    "    \"\"\"\n",
    "    assert num_iterations > num_burn_in\n",
    "    conditional_prob = Factor()\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    print(nodes,edges)\n",
    "    #update evidence\n",
    "    evidencedFactorsDict=update_factor_dict_with_evidence(factors,evidence)\n",
    "    evidencedFactorsDict\n",
    "    # create children dict\n",
    "    markovBlanketDict= {node:[node]+[child for parent,child in edges if parent==node] for node in nodes}\n",
    "    singleFactorsDict={}\n",
    "    # marginalizing to their base prob\n",
    "    for node in nodes:       \n",
    "        factorsToMarginalizeOutList=np.setdiff1d(factors[node].var, [node])\n",
    "        # print(node,markovBlanketDict[node])\n",
    "        singleFactorsDict[node]=factor_marginalize(factors[node],factorsToMarginalizeOutList)\n",
    "        #singleFactorsDict[node]=currentNodeFactor\n",
    "        print(singleFactorsDict[node])\n",
    "    \n",
    "    nodes=[n for n in nodes if n not in evidence.keys()]\n",
    "\n",
    "    markovSeperatedDict={}\n",
    "    for node in nodes:\n",
    "        markovJoinedVariablesList=markovBlanketDict[node] \n",
    "        print(node,markovJoinedVariablesList)\n",
    "        currentMarkovFactor=compute_joint_distribution([evidencedFactorsDict[n] for n in markovJoinedVariablesList])\n",
    "        factorsToMarginalizeOutList=np.setdiff1d(currentMarkovFactor.var, markovJoinedVariablesList)\n",
    "        markovSeperatedDict[node]=factor_marginalize(currentMarkovFactor,factorsToMarginalizeOutList)\n",
    "        print(markovSeperatedDict[node])\n",
    "       \n",
    "    # removing evidence from samping\n",
    "    start_samples={k:v for k,v in copy.deepcopy(initial_samples).items() if k not in evidence.keys()}\n",
    "\n",
    "    burnedInSamples={}\n",
    "    # num_iterations, num_burn_in\n",
    "    for _ in tqdm(range(num_burn_in)):\n",
    "        burnedInSamples=_sample_step(nodes=nodes, factors=singleFactorsDict, in_samples=start_samples)\n",
    "\n",
    "    samplesList=[]\n",
    "    for _ in tqdm(range(num_iterations-num_burn_in)):\n",
    "        samplesList.append(_sample_step(nodes=nodes, factors=singleFactorsDict, in_samples=burnedInSamples))\n",
    "    \n",
    "    #for sample in samplesList:\n",
    "    #    for k,v in evidence.items():\n",
    "    #        sample[k]=v\n",
    "\n",
    "    df1=pd.DataFrame(samplesList)\n",
    "    grouped = df1.groupby(list(df1.columns)).size().reset_index(name='counts')\n",
    "    problemVal=np.zeros(len(node_factors[0].val))\n",
    "    problemVal[grouped.apply(lambda x: assignment_to_index(x[df1.columns].to_numpy(),node_factors[0].card[nodes]),axis=1)]=grouped.counts\n",
    "\n",
    "    conditional_prob=Factor(var=nodes,card=factors[0].card[nodes],val=problemVal/np.sum(problemVal))\n",
    "\n",
    "\n",
    "    \"\"\" END YOUR CODE HERE \"\"\"\n",
    "\n",
    "    return conditional_prob\n",
    "\n",
    "conditional_probability = _get_conditional_probability(nodes=nodes, edges=edges, factors=node_factors,\n",
    "                                                           evidence=evidence, initial_samples=initial_samples,\n",
    "                                                           num_iterations=num_iterations, num_burn_in=num_burn_in)\n",
    "\n",
    "conditional_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_factors[0].card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]),)\n",
      "(array([1]),)\n",
      "(array([3]),)\n",
      "(array([4]),)\n"
     ]
    }
   ],
   "source": [
    "for n in [0,1,3,4]:\n",
    "    print(np.where(node_factors[0].var==n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.in1d(node_factors[0].var, [0,1,3,4]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_factors[0].card[[0,1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Factor containing 5 variables\n",
       " -------------------------------------\n",
       " | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       " -------------------------------------\n",
       " |  0   0   0   0   0  |           0 |\n",
       " |  1   0   0   0   0  |           0 |\n",
       " |  0   1   0   0   0  |           0 |\n",
       " |  1   1   0   0   0  |           0 |\n",
       " |  0   0   1   0   0  |   0.0367647 |\n",
       " |  1   0   1   0   0  |  0.00490196 |\n",
       " |  0   1   1   0   0  |   0.0231481 |\n",
       " |  1   1   1   0   0  |   0.0185185 |\n",
       " |  0   0   2   0   0  |           0 |\n",
       " |  1   0   2   0   0  |           0 |\n",
       " |  0   1   2   0   0  |           0 |\n",
       " |  1   1   2   0   0  |           0 |\n",
       " |  0   0   0   1   0  |           0 |\n",
       " |  1   0   0   1   0  |           0 |\n",
       " |  0   1   0   1   0  |           0 |\n",
       " |  1   1   0   1   0  |           0 |\n",
       " |  0   0   1   1   0  |   0.0367647 |\n",
       " |  1   0   1   1   0  |  0.00490196 |\n",
       " |  0   1   1   1   0  |   0.0231481 |\n",
       " |  1   1   1   1   0  |   0.0185185 |\n",
       " |  0   0   2   1   0  |           0 |\n",
       " |  1   0   2   1   0  |           0 |\n",
       " |  0   1   2   1   0  |           0 |\n",
       " |  1   1   2   1   0  |           0 |\n",
       " |  0   0   0   0   1  |           0 |\n",
       " |  1   0   0   0   1  |           0 |\n",
       " |  0   1   0   0   1  |           0 |\n",
       " |  1   1   0   0   1  |           0 |\n",
       " |  0   0   1   0   1  |   0.0367647 |\n",
       " |  1   0   1   0   1  |  0.00490196 |\n",
       " |  0   1   1   0   1  |   0.0231481 |\n",
       " |  1   1   1   0   1  |   0.0185185 |\n",
       " |  0   0   2   0   1  |           0 |\n",
       " |  1   0   2   0   1  |           0 |\n",
       " |  0   1   2   0   1  |           0 |\n",
       " |  1   1   2   0   1  |           0 |\n",
       " |  0   0   0   1   1  |           0 |\n",
       " |  1   0   0   1   1  |           0 |\n",
       " |  0   1   0   1   1  |           0 |\n",
       " |  1   1   0   1   1  |           0 |\n",
       " |  0   0   1   1   1  |   0.0367647 |\n",
       " |  1   0   1   1   1  |  0.00490196 |\n",
       " |  0   1   1   1   1  |   0.0231481 |\n",
       " |  1   1   1   1   1  |   0.0185185 |\n",
       " |  0   0   2   1   1  |           0 |\n",
       " |  1   0   2   1   1  |           0 |\n",
       " |  0   1   2   1   1  |           0 |\n",
       " |  1   1   2   1   1  |           0 |\n",
       " -------------------------------------\n",
       " ,\n",
       " 1: Factor containing 5 variables\n",
       " -------------------------------------\n",
       " | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       " -------------------------------------\n",
       " |  0   0   0   0   0  |           0 |\n",
       " |  1   0   0   0   0  |           0 |\n",
       " |  0   1   0   0   0  |           0 |\n",
       " |  1   1   0   0   0  |           0 |\n",
       " |  0   0   1   0   0  |   0.0394425 |\n",
       " |  1   0   1   0   0  |    0.031133 |\n",
       " |  0   1   1   0   0  |   0.0022242 |\n",
       " |  1   1   1   0   0  |   0.0105337 |\n",
       " |  0   0   2   0   0  |           0 |\n",
       " |  1   0   2   0   0  |           0 |\n",
       " |  0   1   2   0   0  |           0 |\n",
       " |  1   1   2   0   0  |           0 |\n",
       " |  0   0   0   1   0  |           0 |\n",
       " |  1   0   0   1   0  |           0 |\n",
       " |  0   1   0   1   0  |           0 |\n",
       " |  1   1   0   1   0  |           0 |\n",
       " |  0   0   1   1   0  |   0.0394425 |\n",
       " |  1   0   1   1   0  |    0.031133 |\n",
       " |  0   1   1   1   0  |   0.0022242 |\n",
       " |  1   1   1   1   0  |   0.0105337 |\n",
       " |  0   0   2   1   0  |           0 |\n",
       " |  1   0   2   1   0  |           0 |\n",
       " |  0   1   2   1   0  |           0 |\n",
       " |  1   1   2   1   0  |           0 |\n",
       " |  0   0   0   0   1  |           0 |\n",
       " |  1   0   0   0   1  |           0 |\n",
       " |  0   1   0   0   1  |           0 |\n",
       " |  1   1   0   0   1  |           0 |\n",
       " |  0   0   1   0   1  |  0.00788288 |\n",
       " |  1   0   1   0   1  |  0.00155971 |\n",
       " |  0   1   1   0   1  |   0.0337838 |\n",
       " |  1   1   1   0   1  |    0.040107 |\n",
       " |  0   0   2   0   1  |           0 |\n",
       " |  1   0   2   0   1  |           0 |\n",
       " |  0   1   2   0   1  |           0 |\n",
       " |  1   1   2   0   1  |           0 |\n",
       " |  0   0   0   1   1  |           0 |\n",
       " |  1   0   0   1   1  |           0 |\n",
       " |  0   1   0   1   1  |           0 |\n",
       " |  1   1   0   1   1  |           0 |\n",
       " |  0   0   1   1   1  |  0.00788288 |\n",
       " |  1   0   1   1   1  |  0.00155971 |\n",
       " |  0   1   1   1   1  |   0.0337838 |\n",
       " |  1   1   1   1   1  |    0.040107 |\n",
       " |  0   0   2   1   1  |           0 |\n",
       " |  1   0   2   1   1  |           0 |\n",
       " |  0   1   2   1   1  |           0 |\n",
       " |  1   1   2   1   1  |           0 |\n",
       " -------------------------------------\n",
       " ,\n",
       " 2: Factor containing 5 variables\n",
       " -------------------------------------\n",
       " | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       " -------------------------------------\n",
       " |  0   0   0   0   0  |           0 |\n",
       " |  1   0   0   0   0  |           0 |\n",
       " |  0   1   0   0   0  |           0 |\n",
       " |  1   1   0   0   0  |           0 |\n",
       " |  0   0   1   0   0  |   0.0205339 |\n",
       " |  1   0   1   0   0  |   0.0141044 |\n",
       " |  0   1   1   0   0  |  0.00783208 |\n",
       " |  1   1   1   0   0  |   0.0203804 |\n",
       " |  0   0   2   0   0  |           0 |\n",
       " |  1   0   2   0   0  |           0 |\n",
       " |  0   1   2   0   0  |           0 |\n",
       " |  1   1   2   0   0  |           0 |\n",
       " |  0   0   0   1   0  |           0 |\n",
       " |  1   0   0   1   0  |           0 |\n",
       " |  0   1   0   1   0  |           0 |\n",
       " |  1   1   0   1   0  |           0 |\n",
       " |  0   0   1   1   0  |   0.0292398 |\n",
       " |  1   0   1   1   0  |  0.00349569 |\n",
       " |  0   1   1   1   0  |   0.0464109 |\n",
       " |  1   1   1   1   0  |   0.0178006 |\n",
       " |  0   0   2   1   0  |           0 |\n",
       " |  1   0   2   1   0  |           0 |\n",
       " |  0   1   2   1   0  |           0 |\n",
       " |  1   1   2   1   0  |           0 |\n",
       " |  0   0   0   0   1  |           0 |\n",
       " |  1   0   0   0   1  |           0 |\n",
       " |  0   1   0   0   1  |           0 |\n",
       " |  1   1   0   0   1  |           0 |\n",
       " |  0   0   1   0   1  |   0.0205339 |\n",
       " |  1   0   1   0   1  |   0.0141044 |\n",
       " |  0   1   1   0   1  |  0.00783208 |\n",
       " |  1   1   1   0   1  |   0.0203804 |\n",
       " |  0   0   2   0   1  |           0 |\n",
       " |  1   0   2   0   1  |           0 |\n",
       " |  0   1   2   0   1  |           0 |\n",
       " |  1   1   2   0   1  |           0 |\n",
       " |  0   0   0   1   1  |           0 |\n",
       " |  1   0   0   1   1  |           0 |\n",
       " |  0   1   0   1   1  |           0 |\n",
       " |  1   1   0   1   1  |           0 |\n",
       " |  0   0   1   1   1  |   0.0292398 |\n",
       " |  1   0   1   1   1  |  0.00349569 |\n",
       " |  0   1   1   1   1  |   0.0464109 |\n",
       " |  1   1   1   1   1  |   0.0178006 |\n",
       " |  0   0   2   1   1  |           0 |\n",
       " |  1   0   2   1   1  |           0 |\n",
       " |  0   1   2   1   1  |           0 |\n",
       " |  1   1   2   1   1  |           0 |\n",
       " -------------------------------------\n",
       " ,\n",
       " 3: Factor containing 5 variables\n",
       " -------------------------------------\n",
       " | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       " -------------------------------------\n",
       " |  0   0   0   0   0  |           0 |\n",
       " |  1   0   0   0   0  |           0 |\n",
       " |  0   1   0   0   0  |           0 |\n",
       " |  1   1   0   0   0  |           0 |\n",
       " |  0   0   1   0   0  |   0.0166667 |\n",
       " |  1   0   1   0   0  |   0.0166667 |\n",
       " |  0   1   1   0   0  |   0.0166667 |\n",
       " |  1   1   1   0   0  |   0.0166667 |\n",
       " |  0   0   2   0   0  |           0 |\n",
       " |  1   0   2   0   0  |           0 |\n",
       " |  0   1   2   0   0  |           0 |\n",
       " |  1   1   2   0   0  |           0 |\n",
       " |  0   0   0   1   0  |           0 |\n",
       " |  1   0   0   1   0  |           0 |\n",
       " |  0   1   0   1   0  |           0 |\n",
       " |  1   1   0   1   0  |           0 |\n",
       " |  0   0   1   1   0  |       0.025 |\n",
       " |  1   0   1   1   0  |       0.025 |\n",
       " |  0   1   1   1   0  |       0.025 |\n",
       " |  1   1   1   1   0  |       0.025 |\n",
       " |  0   0   2   1   0  |           0 |\n",
       " |  1   0   2   1   0  |           0 |\n",
       " |  0   1   2   1   0  |           0 |\n",
       " |  1   1   2   1   0  |           0 |\n",
       " |  0   0   0   0   1  |           0 |\n",
       " |  1   0   0   0   1  |           0 |\n",
       " |  0   1   0   0   1  |           0 |\n",
       " |  1   1   0   0   1  |           0 |\n",
       " |  0   0   1   0   1  |   0.0166667 |\n",
       " |  1   0   1   0   1  |   0.0166667 |\n",
       " |  0   1   1   0   1  |   0.0166667 |\n",
       " |  1   1   1   0   1  |   0.0166667 |\n",
       " |  0   0   2   0   1  |           0 |\n",
       " |  1   0   2   0   1  |           0 |\n",
       " |  0   1   2   0   1  |           0 |\n",
       " |  1   1   2   0   1  |           0 |\n",
       " |  0   0   0   1   1  |           0 |\n",
       " |  1   0   0   1   1  |           0 |\n",
       " |  0   1   0   1   1  |           0 |\n",
       " |  1   1   0   1   1  |           0 |\n",
       " |  0   0   1   1   1  |       0.025 |\n",
       " |  1   0   1   1   1  |       0.025 |\n",
       " |  0   1   1   1   1  |       0.025 |\n",
       " |  1   1   1   1   1  |       0.025 |\n",
       " |  0   0   2   1   1  |           0 |\n",
       " |  1   0   2   1   1  |           0 |\n",
       " |  0   1   2   1   1  |           0 |\n",
       " |  1   1   2   1   1  |           0 |\n",
       " -------------------------------------\n",
       " ,\n",
       " 4: Factor containing 5 variables\n",
       " -------------------------------------\n",
       " | X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       " -------------------------------------\n",
       " |  0   0   0   0   0  |           0 |\n",
       " |  1   0   0   0   0  |           0 |\n",
       " |  0   1   0   0   0  |           0 |\n",
       " |  1   1   0   0   0  |           0 |\n",
       " |  0   0   1   0   0  |   0.0395833 |\n",
       " |  1   0   1   0   0  |   0.0395833 |\n",
       " |  0   1   1   0   0  |  0.00833333 |\n",
       " |  1   1   1   0   0  |  0.00833333 |\n",
       " |  0   0   2   0   0  |           0 |\n",
       " |  1   0   2   0   0  |           0 |\n",
       " |  0   1   2   0   0  |           0 |\n",
       " |  1   1   2   0   0  |           0 |\n",
       " |  0   0   0   1   0  |           0 |\n",
       " |  1   0   0   1   0  |           0 |\n",
       " |  0   1   0   1   0  |           0 |\n",
       " |  1   1   0   1   0  |           0 |\n",
       " |  0   0   1   1   0  |   0.0395833 |\n",
       " |  1   0   1   1   0  |   0.0395833 |\n",
       " |  0   1   1   1   0  |  0.00833333 |\n",
       " |  1   1   1   1   0  |  0.00833333 |\n",
       " |  0   0   2   1   0  |           0 |\n",
       " |  1   0   2   1   0  |           0 |\n",
       " |  0   1   2   1   0  |           0 |\n",
       " |  1   1   2   1   0  |           0 |\n",
       " |  0   0   0   0   1  |           0 |\n",
       " |  1   0   0   0   1  |           0 |\n",
       " |  0   1   0   0   1  |           0 |\n",
       " |  1   1   0   0   1  |           0 |\n",
       " |  0   0   1   0   1  |  0.00208333 |\n",
       " |  1   0   1   0   1  |  0.00208333 |\n",
       " |  0   1   1   0   1  |   0.0333333 |\n",
       " |  1   1   1   0   1  |   0.0333333 |\n",
       " |  0   0   2   0   1  |           0 |\n",
       " |  1   0   2   0   1  |           0 |\n",
       " |  0   1   2   0   1  |           0 |\n",
       " |  1   1   2   0   1  |           0 |\n",
       " |  0   0   0   1   1  |           0 |\n",
       " |  1   0   0   1   1  |           0 |\n",
       " |  0   1   0   1   1  |           0 |\n",
       " |  1   1   0   1   1  |           0 |\n",
       " |  0   0   1   1   1  |  0.00208333 |\n",
       " |  1   0   1   1   1  |  0.00208333 |\n",
       " |  0   1   1   1   1  |   0.0333333 |\n",
       " |  1   1   1   1   1  |   0.0333333 |\n",
       " |  0   0   2   1   1  |           0 |\n",
       " |  1   0   2   1   1  |           0 |\n",
       " |  0   1   2   1   1  |           0 |\n",
       " |  1   1   2   1   1  |           0 |\n",
       " -------------------------------------\n",
       " }"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update evidence\n",
    "evidencedFactorsDict=update_factor_dict_with_evidence(node_factors,evidence)\n",
    "evidencedFactorsDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 2], 1: [1, 2, 4], 2: [2, 3], 3: [3], 4: [4]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create children dict\n",
    "markovBlanketDict= {node:[node]+[child for parent,child in edges if parent==node] for node in nodes}\n",
    "markovBlanketDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 2, 4]\n",
      "[2, 3]\n",
      "[3]\n",
      "[4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: Factor containing 2 variables\n",
       " -------------------------\n",
       " | X_0 X_2 | Probability |\n",
       " -------------------------\n",
       " |  0   0  |           0 |\n",
       " |  1   0  |           0 |\n",
       " |  0   1  |    0.718954 |\n",
       " |  1   1  |    0.281046 |\n",
       " |  0   2  |           0 |\n",
       " |  1   2  |           0 |\n",
       " -------------------------\n",
       " ,\n",
       " 1: Factor containing 3 variables\n",
       " -----------------------------\n",
       " | X_1 X_2 X_4 | Probability |\n",
       " -----------------------------\n",
       " |  0   0   0  |           0 |\n",
       " |  1   0   0  |           0 |\n",
       " |  0   1   0  |    0.423453 |\n",
       " |  1   1   0  |   0.0765474 |\n",
       " |  0   2   0  |           0 |\n",
       " |  1   2   0  |           0 |\n",
       " |  0   0   1  |           0 |\n",
       " |  1   0   1  |           0 |\n",
       " |  0   1   1  |   0.0566556 |\n",
       " |  1   1   1  |    0.443344 |\n",
       " |  0   2   1  |           0 |\n",
       " |  1   2   1  |           0 |\n",
       " -----------------------------\n",
       " ,\n",
       " 2: Factor containing 2 variables\n",
       " -------------------------\n",
       " | X_2 X_3 | Probability |\n",
       " -------------------------\n",
       " |  0   0  |           0 |\n",
       " |  1   0  |    0.393314 |\n",
       " |  2   0  |           0 |\n",
       " |  0   1  |           0 |\n",
       " |  1   1  |    0.606686 |\n",
       " |  2   1  |           0 |\n",
       " -------------------------\n",
       " ,\n",
       " 3: Factor containing 1 variables\n",
       " ---------------------\n",
       " | X_3 | Probability |\n",
       " ---------------------\n",
       " |  0  |         0.4 |\n",
       " |  1  |         0.6 |\n",
       " ---------------------\n",
       " ,\n",
       " 4: Factor containing 1 variables\n",
       " ---------------------\n",
       " | X_4 | Probability |\n",
       " ---------------------\n",
       " |  0  |       0.575 |\n",
       " |  1  |       0.425 |\n",
       " ---------------------\n",
       " }"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markovBlanketSeperatedFactors={}\n",
    "for node in evidencedFactorsDict.keys():\n",
    "    factorsToMarginalizeOutList=np.setdiff1d(evidencedFactorsDict[node].var, markovBlanketDict[node])\n",
    "    print(markovBlanketDict[node])\n",
    "    markovBlanketSeperatedFactors[node]=factor_marginalize(evidencedFactorsDict[node],factorsToMarginalizeOutList)\n",
    "markovBlanketSeperatedFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Factor containing 2 variables\n",
       " -------------------------\n",
       " | X_0 X_2 | Probability |\n",
       " -------------------------\n",
       " |  0   0  |           0 |\n",
       " |  1   0  |           0 |\n",
       " |  0   1  |    0.718954 |\n",
       " |  1   1  |    0.281046 |\n",
       " |  0   2  |           0 |\n",
       " |  1   2  |           0 |\n",
       " -------------------------\n",
       " ,\n",
       " Factor containing 2 variables\n",
       " -------------------------\n",
       " | X_0 X_2 | Probability |\n",
       " -------------------------\n",
       " |  0   0  |           0 |\n",
       " |  1   0  |           0 |\n",
       " |  0   1  |    0.718954 |\n",
       " |  1   1  |    0.281046 |\n",
       " |  0   2  |           0 |\n",
       " |  1   2  |           0 |\n",
       " -------------------------\n",
       " )"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markovBlanketSeperatedFactors[0],factor_marginalize(markovBlanketSeperatedFactors[0],[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), {0: 0, 1: 0, 2: 0, 3: 0, 4: 0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes,initial_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Factor containing 1 variables\n",
       "---------------------\n",
       "| X_0 | Probability |\n",
       "---------------------\n",
       "|  0  |    0.718954 |\n",
       "|  1  |    0.281046 |\n",
       "---------------------\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentVariable=nodes[0]\n",
    "fixedVariablesDict={k:v for k,v in initial_samples.items() if k!=currentVariable}\n",
    "for key in fixedVariablesDict.keys():\n",
    "    if evidence.get(key):\n",
    "        fixedVariablesDict[key]=evidence[key]\n",
    "#evidence is a problem\n",
    "currentFactor=factor_evidence(markovBlanketSeperatedFactors[currentVariable],fixedVariablesDict)\n",
    "factor_marginalize(currentFactor,np.setdiff1d(currentFactor.var, [currentVariable]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0 2] [0] [2]\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_0 | Probability |\n",
      "---------------------\n",
      "|  0  |    0.718954 |\n",
      "|  1  |    0.281046 |\n",
      "---------------------\n",
      "\n",
      " 0 {0: 0, 1: 0, 2: 1, 3: 0, 4: 0}\n",
      "1 [1 2 4] [1] [2 4]\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_1 | Probability |\n",
      "---------------------\n",
      "|  0  |    0.846905 |\n",
      "|  1  |    0.153095 |\n",
      "---------------------\n",
      "\n",
      " 0 {0: 0, 1: 0, 2: 1, 3: 0, 4: 0}\n",
      "2 [2 3] [2] [3]\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_2 | Probability |\n",
      "---------------------\n",
      "|  0  |           0 |\n",
      "|  1  |           1 |\n",
      "|  2  |           0 |\n",
      "---------------------\n",
      "\n",
      " 1 {0: 0, 1: 0, 2: 1, 3: 0, 4: 0}\n",
      "3 [3] [3] []\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_3 | Probability |\n",
      "---------------------\n",
      "|  0  |         0.4 |\n",
      "|  1  |         0.6 |\n",
      "---------------------\n",
      "\n",
      " 1 {0: 0, 1: 0, 2: 1, 3: 1, 4: 0}\n",
      "4 [4] [4] []\n",
      "Factor containing 1 variables\n",
      "---------------------\n",
      "| X_4 | Probability |\n",
      "---------------------\n",
      "|  0  |       0.575 |\n",
      "|  1  |       0.425 |\n",
      "---------------------\n",
      "\n",
      " 0 {0: 0, 1: 0, 2: 1, 3: 1, 4: 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_samples=copy.deepcopy(initial_samples)\n",
    "for key in current_samples.keys():\n",
    "    if evidence.get(key):\n",
    "        current_samples[key]=evidence[key]\n",
    "\n",
    "for node in nodes:\n",
    "    currentVariable=node\n",
    "    fixedVariablesDict={k:v for k,v in current_samples.items() if k!=currentVariable}\n",
    "    #evidence is a problem\n",
    "    currentFactor=factor_evidence(markovBlanketSeperatedFactors[currentVariable],fixedVariablesDict)\n",
    "    variable_factor=factor_marginalize(currentFactor,np.setdiff1d(currentFactor.var, [currentVariable]) )\n",
    "    print(node,currentFactor.var, [currentVariable],np.setdiff1d(currentFactor.var, [currentVariable]) )\n",
    "    proposal_distribution = variable_factor.val\n",
    "    sample_space = np.arange(len(proposal_distribution))\n",
    "    # Sample a value using the proposal distribution\n",
    "    sampled_value = np.random.choice(sample_space, p=proposal_distribution)\n",
    "    current_samples[node]=sampled_value\n",
    "    print(variable_factor,sampled_value,current_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1644.49it/s]\n",
      "100%|██████████| 10000/10000 [00:06<00:00, 1627.95it/s]\n"
     ]
    }
   ],
   "source": [
    "#update evidence\n",
    "evidencedFactorsDict=update_factor_dict_with_evidence(node_factors,evidence)\n",
    "evidencedFactorsDict\n",
    "# create children dict\n",
    "markovBlanketDict= {node:[node]+[child for parent,child in edges if parent==node] for node in nodes}\n",
    "markovBlanketSeperatedFactors={}\n",
    "# finding valid nodes post markov blankets treatment\n",
    "for node in evidencedFactorsDict.keys():\n",
    "    factorsToMarginalizeOutList=np.setdiff1d(evidencedFactorsDict[node].var, markovBlanketDict[node])\n",
    "    # print(markovBlanketDict[node])\n",
    "    markovBlanketSeperatedFactors[node]=factor_marginalize(evidencedFactorsDict[node],factorsToMarginalizeOutList)\n",
    "\n",
    "\n",
    "def _sample_step(nodes, factors, in_samples):\n",
    "    \"\"\"\n",
    "    Performs gibbs sampling for a single iteration. Returns a sample for each node\n",
    "\n",
    "    Args:\n",
    "        nodes: numpy array of nodes\n",
    "        factors: dictionary of factors e.g. factors[x1] returns the local factor for x1\n",
    "        in_samples: dictionary of input samples (from previous iteration)\n",
    "\n",
    "    Returns:\n",
    "        dictionary of output samples where samples[x1] returns the sample for x1.\n",
    "    \"\"\"\n",
    "    samples = copy.deepcopy(in_samples)\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    for node in nodes:\n",
    "        currentVariable=node\n",
    "        fixedVariablesDict={k:v for k,v in samples.items() if k!=currentVariable}\n",
    "        #evidence is a problem\n",
    "        currentFactor=factor_evidence(factors[currentVariable],fixedVariablesDict)\n",
    "        variable_factor=factor_marginalize(currentFactor,np.setdiff1d(currentFactor.var, [currentVariable]) )\n",
    "        # print(node,currentFactor.var, [currentVariable],np.setdiff1d(currentFactor.var, [currentVariable]) )\n",
    "        proposal_distribution = variable_factor.val\n",
    "        sample_space = np.arange(len(proposal_distribution))\n",
    "        # Sample a value using the proposal distribution\n",
    "        sampled_value = np.random.choice(sample_space, p=proposal_distribution)\n",
    "        samples[node]=sampled_value\n",
    "        #print(variable_factor,sampled_value,current_samples)\n",
    "\n",
    "    \"\"\" END YOUR CODE HERE \"\"\"\n",
    "\n",
    "    return samples\n",
    "\n",
    "start_samples=copy.deepcopy(initial_samples)\n",
    "for key in start_samples.keys():\n",
    "    if evidence.get(key):\n",
    "        start_samples[key]=evidence[key]\n",
    "\n",
    "burnedInSamples={}\n",
    "# num_iterations, num_burn_in\n",
    "for _ in tqdm(range(num_burn_in)):\n",
    "    burnedInSamples=_sample_step(nodes=nodes, factors=markovBlanketSeperatedFactors, in_samples=start_samples)\n",
    "\n",
    "samplesList=[]\n",
    "for _ in tqdm(range(num_iterations)):\n",
    "    samplesList.append(_sample_step(nodes=nodes, factors=markovBlanketSeperatedFactors, in_samples=burnedInSamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.282700</td>\n",
       "      <td>0.886200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.594500</td>\n",
       "      <td>0.42410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.450334</td>\n",
       "      <td>0.317584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.491013</td>\n",
       "      <td>0.49423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1        2             3            4\n",
       "count  10000.000000  10000.000000  10000.0  10000.000000  10000.00000\n",
       "mean       0.282700      0.886200      1.0      0.594500      0.42410\n",
       "std        0.450334      0.317584      0.0      0.491013      0.49423\n",
       "min        0.000000      0.000000      1.0      0.000000      0.00000\n",
       "25%        0.000000      1.000000      1.0      0.000000      0.00000\n",
       "50%        0.000000      1.000000      1.0      1.000000      0.00000\n",
       "75%        1.000000      1.000000      1.0      1.000000      1.00000\n",
       "max        1.000000      1.000000      1.0      1.000000      1.00000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df1=pd.DataFrame(samplesList)\n",
    "\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.9412\n",
       "1    0.8022\n",
       "2    0.7133\n",
       "3    0.7061\n",
       "4    0.2490\n",
       "5    0.4173\n",
       "6    0.6942\n",
       "7    0.6245\n",
       "8    0.5198\n",
       "9    0.5554\n",
       "dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  2  3  4  counts\n",
       "0   0  0  1  0  0     179\n",
       "1   0  0  1  0  1     156\n",
       "2   0  0  1  1  0     270\n",
       "3   0  0  1  1  1     223\n",
       "4   0  1  1  0  0    1500\n",
       "5   0  1  1  0  1    1068\n",
       "6   0  1  1  1  0    2185\n",
       "7   0  1  1  1  1    1592\n",
       "8   1  0  1  0  0      71\n",
       "9   1  0  1  0  1      60\n",
       "10  1  0  1  1  0     115\n",
       "11  1  0  1  1  1      64\n",
       "12  1  1  1  0  0     573\n",
       "13  1  1  1  0  1     448\n",
       "14  1  1  1  1  0     866\n",
       "15  1  1  1  1  1     630"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding unique counts of patterns\n",
    "df1=pd.DataFrame(samplesList)\n",
    "grouped = df1.groupby(list(df1.columns)).size().reset_index(name='counts')\n",
    "\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4\n",
       "1     28\n",
       "2     16\n",
       "3     40\n",
       "4      6\n",
       "5     30\n",
       "6     18\n",
       "7     42\n",
       "8      5\n",
       "9     29\n",
       "10    17\n",
       "11    41\n",
       "12     7\n",
       "13    31\n",
       "14    19\n",
       "15    43\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding index of assignment\n",
    "grouped.apply(lambda x: assignment_to_index(x[df1.columns].to_numpy(),node_factors[0].card),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    0.,  179.,   71., 1500.,  573.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,  270.,  115.,\n",
       "       2185.,  866.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,  156.,   60., 1068.,  448.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,  223.,   64., 1592.,  630.,    0.,\n",
       "          0.,    0.,    0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(samplesList)\n",
    "grouped = df1.groupby(list(df1.columns)).size().reset_index(name='counts')\n",
    "problemVal=np.zeros(len(node_factors[0].val))\n",
    "problemVal[grouped.apply(lambda x: assignment_to_index(x[df1.columns].to_numpy(),node_factors[0].card),axis=1)]=grouped.counts\n",
    "problemVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Factor containing 5 variables\n",
       "-------------------------------------\n",
       "| X_0 X_1 X_2 X_3 X_4 | Probability |\n",
       "-------------------------------------\n",
       "|  0   0   0   0   0  |           0 |\n",
       "|  1   0   0   0   0  |           0 |\n",
       "|  0   1   0   0   0  |           0 |\n",
       "|  1   1   0   0   0  |           0 |\n",
       "|  0   0   1   0   0  |      0.0179 |\n",
       "|  1   0   1   0   0  |      0.0071 |\n",
       "|  0   1   1   0   0  |        0.15 |\n",
       "|  1   1   1   0   0  |      0.0573 |\n",
       "|  0   0   2   0   0  |           0 |\n",
       "|  1   0   2   0   0  |           0 |\n",
       "|  0   1   2   0   0  |           0 |\n",
       "|  1   1   2   0   0  |           0 |\n",
       "|  0   0   0   1   0  |           0 |\n",
       "|  1   0   0   1   0  |           0 |\n",
       "|  0   1   0   1   0  |           0 |\n",
       "|  1   1   0   1   0  |           0 |\n",
       "|  0   0   1   1   0  |       0.027 |\n",
       "|  1   0   1   1   0  |      0.0115 |\n",
       "|  0   1   1   1   0  |      0.2185 |\n",
       "|  1   1   1   1   0  |      0.0866 |\n",
       "|  0   0   2   1   0  |           0 |\n",
       "|  1   0   2   1   0  |           0 |\n",
       "|  0   1   2   1   0  |           0 |\n",
       "|  1   1   2   1   0  |           0 |\n",
       "|  0   0   0   0   1  |           0 |\n",
       "|  1   0   0   0   1  |           0 |\n",
       "|  0   1   0   0   1  |           0 |\n",
       "|  1   1   0   0   1  |           0 |\n",
       "|  0   0   1   0   1  |      0.0156 |\n",
       "|  1   0   1   0   1  |       0.006 |\n",
       "|  0   1   1   0   1  |      0.1068 |\n",
       "|  1   1   1   0   1  |      0.0448 |\n",
       "|  0   0   2   0   1  |           0 |\n",
       "|  1   0   2   0   1  |           0 |\n",
       "|  0   1   2   0   1  |           0 |\n",
       "|  1   1   2   0   1  |           0 |\n",
       "|  0   0   0   1   1  |           0 |\n",
       "|  1   0   0   1   1  |           0 |\n",
       "|  0   1   0   1   1  |           0 |\n",
       "|  1   1   0   1   1  |           0 |\n",
       "|  0   0   1   1   1  |      0.0223 |\n",
       "|  1   0   1   1   1  |      0.0064 |\n",
       "|  0   1   1   1   1  |      0.1592 |\n",
       "|  1   1   1   1   1  |       0.063 |\n",
       "|  0   0   2   1   1  |           0 |\n",
       "|  1   0   2   1   1  |           0 |\n",
       "|  0   1   2   1   1  |           0 |\n",
       "|  1   1   2   1   1  |           0 |\n",
       "-------------------------------------\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFactor=Factor(var=node_factors[0].var,card=node_factors[0].card,val=problemVal/np.sum(problemVal))\n",
    "testFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Factor containing 4 variables\n",
       "---------------------------------\n",
       "| X_0 X_1 X_3 X_4 | Probability |\n",
       "---------------------------------\n",
       "|  0   0   0   0  |      0.0179 |\n",
       "|  1   0   0   0  |      0.0071 |\n",
       "|  0   1   0   0  |        0.15 |\n",
       "|  1   1   0   0  |      0.0573 |\n",
       "|  0   0   1   0  |       0.027 |\n",
       "|  1   0   1   0  |      0.0115 |\n",
       "|  0   1   1   0  |      0.2185 |\n",
       "|  1   1   1   0  |      0.0866 |\n",
       "|  0   0   0   1  |      0.0156 |\n",
       "|  1   0   0   1  |       0.006 |\n",
       "|  0   1   0   1  |      0.1068 |\n",
       "|  1   1   0   1  |      0.0448 |\n",
       "|  0   0   1   1  |      0.0223 |\n",
       "|  1   0   1   1  |      0.0064 |\n",
       "|  0   1   1   1  |      0.1592 |\n",
       "|  1   1   1   1  |       0.063 |\n",
       "---------------------------------\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_marginalize(factor_evidence(testFactor,{2:1}),[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 640)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped[df1.columns].iloc[0].to_numpy(),node_factors[0].card,assignment_to_index(grouped[df1.columns].iloc[0].to_numpy(),node_factors[0].card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), {})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_factors[0].card,evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "for c in df1.columns:\n",
    "    print(df1[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 1, 2]),\n",
       " 1: array([1, 3]),\n",
       " 2: array([2, 3, 4]),\n",
       " 3: array([3, 5, 6]),\n",
       " 4: array([4, 7, 8]),\n",
       " 5: array([5]),\n",
       " 6: array([6, 9]),\n",
       " 7: array([7, 8]),\n",
       " 8: array([8, 9]),\n",
       " 9: array([9])}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:v.var for k,v in markovBlanketSeperatedFactors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Factor containing 3 variables\n",
       " -----------------------------\n",
       " | X_0 X_1 X_2 | Probability |\n",
       " -----------------------------\n",
       " |  0   0   0  |   0.0241935 |\n",
       " |  1   0   0  |    0.225806 |\n",
       " |  0   1   0  |        0.05 |\n",
       " |  1   1   0  |         0.2 |\n",
       " |  0   0   1  |  0.00652174 |\n",
       " |  1   0   1  |    0.243478 |\n",
       " |  0   1   1  |   0.0147059 |\n",
       " |  1   1   1  |    0.235294 |\n",
       " -----------------------------\n",
       " ,\n",
       " 1: Factor containing 2 variables\n",
       " -------------------------\n",
       " | X_1 X_3 | Probability |\n",
       " -------------------------\n",
       " |  0   0  |   0.0970826 |\n",
       " |  1   0  |    0.402917 |\n",
       " |  0   1  |    0.290355 |\n",
       " |  1   1  |    0.209645 |\n",
       " -------------------------\n",
       " ,\n",
       " 2: Factor containing 3 variables\n",
       " -----------------------------\n",
       " | X_2 X_3 X_4 | Probability |\n",
       " -----------------------------\n",
       " |  0   0   0  |   0.0737932 |\n",
       " |  1   0   0  |    0.176207 |\n",
       " |  0   1   0  |   0.0859863 |\n",
       " |  1   1   0  |    0.164014 |\n",
       " |  0   0   1  |    0.028281 |\n",
       " |  1   0   1  |    0.221719 |\n",
       " |  0   1   1  |    0.036654 |\n",
       " |  1   1   1  |    0.213346 |\n",
       " -----------------------------\n",
       " ,\n",
       " 3: Factor containing 3 variables\n",
       " -----------------------------\n",
       " | X_3 X_5 X_6 | Probability |\n",
       " -----------------------------\n",
       " |  0   0   0  |   0.0720394 |\n",
       " |  1   0   0  |    0.177961 |\n",
       " |  0   1   0  |    0.177008 |\n",
       " |  1   1   0  |    0.072992 |\n",
       " |  0   0   1  |    0.127986 |\n",
       " |  1   0   1  |    0.122014 |\n",
       " |  0   1   1  |    0.216383 |\n",
       " |  1   1   1  |   0.0336173 |\n",
       " -----------------------------\n",
       " ,\n",
       " 4: Factor containing 3 variables\n",
       " -----------------------------\n",
       " | X_4 X_7 X_8 | Probability |\n",
       " -----------------------------\n",
       " |  0   0   0  |    0.188416 |\n",
       " |  1   0   0  |   0.0615836 |\n",
       " |  0   1   0  |   0.0804196 |\n",
       " |  1   1   0  |     0.16958 |\n",
       " |  0   0   1  |   0.0326087 |\n",
       " |  1   0   1  |    0.217391 |\n",
       " |  0   1   1  |    0.110322 |\n",
       " |  1   1   1  |    0.139678 |\n",
       " -----------------------------\n",
       " ,\n",
       " 5: Factor containing 1 variables\n",
       " ---------------------\n",
       " | X_5 | Probability |\n",
       " ---------------------\n",
       " |  0  |    0.589744 |\n",
       " |  1  |    0.410256 |\n",
       " ---------------------\n",
       " ,\n",
       " 6: Factor containing 2 variables\n",
       " -------------------------\n",
       " | X_6 X_9 | Probability |\n",
       " -------------------------\n",
       " |  0   0  |    0.274604 |\n",
       " |  1   0  |    0.225396 |\n",
       " |  0   1  |    0.153565 |\n",
       " |  1   1  |    0.346435 |\n",
       " -------------------------\n",
       " ,\n",
       " 7: Factor containing 2 variables\n",
       " -------------------------\n",
       " | X_7 X_8 | Probability |\n",
       " -------------------------\n",
       " |  0   0  |        0.19 |\n",
       " |  1   0  |        0.31 |\n",
       " |  0   1  |    0.215542 |\n",
       " |  1   1  |    0.284458 |\n",
       " -------------------------\n",
       " ,\n",
       " 8: Factor containing 2 variables\n",
       " -------------------------\n",
       " | X_8 X_9 | Probability |\n",
       " -------------------------\n",
       " |  0   0  |     0.25656 |\n",
       " |  1   0  |     0.24344 |\n",
       " |  0   1  |    0.235435 |\n",
       " |  1   1  |    0.264565 |\n",
       " -------------------------\n",
       " ,\n",
       " 9: Factor containing 1 variables\n",
       " ---------------------\n",
       " | X_9 | Probability |\n",
       " ---------------------\n",
       " |  0  |    0.448997 |\n",
       " |  1  |    0.551003 |\n",
       " ---------------------\n",
       " }"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markovBlanketSeperatedFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_conditional_probability(nodes, edges, factors, evidence, initial_samples, num_iterations, num_burn_in):\n",
    "    # Initialize sample count dictionary\n",
    "    sample_counts = defaultdict(int)\n",
    "\n",
    "    # Start with initial samples\n",
    "    current_samples = initial_samples\n",
    "\n",
    "    # Perform Gibbs sampling\n",
    "    for _ in range(num_iterations):\n",
    "        # Get a new sample\n",
    "        current_samples = _sample_step(nodes, factors, current_samples)\n",
    "\n",
    "        # We don't count the samples in the burn-in phase\n",
    "        if _ > num_burn_in:\n",
    "            # Convert the current sample to an index or a hashable state\n",
    "            state_index = assignment_to_index(current_samples, nodes)\n",
    "            sample_counts[state_index] += 1\n",
    "\n",
    "    # Now calculate probabilities from counts\n",
    "    total_counts = sum(sample_counts.values())\n",
    "    probabilities = {state: count / total_counts for state, count in sample_counts.items()}\n",
    "\n",
    "    # Convert to a Factor (assuming a function to convert a dictionary to a Factor exists)\n",
    "    conditional_prob = dict_to_factor(probabilities, nodes)\n",
    "\n",
    "    return conditional_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A) = 0.5\n",
      "P(A|B) = 0.5003923107100824\n",
      "P(C|D,E) = 0.48519269776876267\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming `data` is a 10000x5 NumPy array with binary observations (1 or 0)\n",
    "# Columns are A, B, C, D, E in order\n",
    "data = np.random.randint(0, 2, size=(10000, 5))\n",
    "\n",
    "# Calculate P(A)\n",
    "# This is the number of times A occurs (is 1) divided by the total number of observations\n",
    "p_A = np.mean(data[:, 0])\n",
    "\n",
    "# Calculate P(A|B)\n",
    "# This is the number of times both A and B occur together divided by the number of times B occurs\n",
    "p_A_given_B = np.mean(data[:, 0][data[:, 1] == 1])\n",
    "\n",
    "# Calculate P(C|D,E)\n",
    "# This is the number of times C occurs with both D and E occurring divided by the number of times D and E both occur\n",
    "mask_DE = np.logical_and(data[:, 3] == 1, data[:, 4] == 1)  # Create a mask where both D and E are 1\n",
    "p_C_given_DE = np.mean(data[:, 2][mask_DE])\n",
    "\n",
    "print(f\"P(A) = {p_A}\")\n",
    "print(f\"P(A|B) = {p_A_given_B}\")\n",
    "print(f\"P(C|D,E) = {p_C_given_DE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
